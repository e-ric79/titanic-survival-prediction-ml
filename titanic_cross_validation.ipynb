{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVwlKcEOHTRF"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploads=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "df=pd.read_csv('Titanic-Dataset.csv')\n",
        "#cleaning data\n",
        "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
        "df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
        "df = df.dropna()\n",
        "df.head()\n",
        "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "y = df['Survived']\n",
        "print(f\"Data ready: {X.shape[0]} passengers\")"
      ],
      "metadata": {
        "id": "C_hg8249kBRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating models\n",
        "lr=LogisticRegression(max_iter=1000,random_state=42)\n",
        "rf=RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "#5 fold cross validation\n",
        "kfold=KFold(n_splits=5,shuffle=True,random_state=42)\n",
        "#logistic regression CV\n",
        "lr_scores=cross_val_score(lr,X,y,cv=kfold,scoring='accuracy')\n",
        "print(\"LOGISTIC REGRESSION\")\n",
        "print(f\"5 fold cv scores: {lr_scores}\")\n",
        "print(f\"mean accuracy: {lr_scores.mean():.4f}\")\n",
        "print(f\"std deviation: {lr_scores.std():.4f}\")\n",
        "print(f\"Range: {lr_scores.min():.4f}-{lr_scores.max():.4f}\")\n",
        "print(\"\\n\" + \"=\"*50 +\"\\n\")\n",
        "#Random forest cv\n",
        "rf_scores=cross_val_score(rf,X,y,cv=kfold,scoring='accuracy')\n",
        "print(\"RANDOM FOREST\")\n",
        "print(f\"5 fold cv scores: {rf_scores}\")\n",
        "print(f\"mean accuracy: {rf_scores.mean():.4f}\")\n",
        "print(f\"std deviation: {rf_scores.std():.4f}\")\n",
        "print(f\"Range: {rf_scores.min():.4f}-{rf_scores.max():.4f}\")"
      ],
      "metadata": {
        "id": "Z7rU0shEkeaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing cross-validation scores\n",
        "fig,(ax1,ax2)=plt.subplots(1,2 ,figsize=(14,5))\n",
        "#boxplot\n",
        "scores_df=pd.DataFrame({\n",
        "    'Logistic Regression': lr_scores,\n",
        "    'Random Forest': rf_scores\n",
        "})\n",
        "scores_df.plot(kind='box',ax=ax1)\n",
        "ax1.set_ylabel(\"Accuracy score\")\n",
        "ax1.set_title(\"Model Stability Comparison (5-Fold CV)\")\n",
        "ax1.axhline(y=0.8,color='r',linestyle='--',alpha=0.3,label='80% baseline')\n",
        "ax1.legend()\n",
        "#barplot with error bars\n",
        "means = [lr_scores.mean(), rf_scores.mean()]\n",
        "stds = [lr_scores.std(), rf_scores.std()]\n",
        "models = ['Logistic\\nRegression', 'Random\\nForest']\n",
        "ax2.bar(models,means,yerr=stds,alpha=0.7,capsize=10,color=['blue','green'])\n",
        "ax2.set_ylabel(\"Mean accuracy\")\n",
        "ax2.set_ylim([0.75,0.85])\n",
        "ax2.set_title(\"Mean Accuracy with Standard deviation\")\n",
        "ax2.axhline(y=0.8,color='r',linestyle='--',alpha=0.3)\n",
        "#add value labels\n",
        "for i, (mean, std) in enumerate(zip(means, stds)):\n",
        "    ax2.text(i, mean + std + 0.005, f'{mean:.2%}\\n±{std:.2%}',\n",
        "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONCLUSION:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Random Forest is MORE ACCURATE: {rf_scores.mean():.2%}\")\n",
        "print(f\"Random Forest is MORE STABLE: std={rf_scores.std():.4f}\")\n",
        "print(f\"Winner: Random Forest\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "8KO09oHDr93e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-Validation: Robust Model Evaluation\n",
        "\n",
        "## Why Cross-Validation?\n",
        "\n",
        "Single train/test split can be misleading:\n",
        "- Lucky split → overestimate accuracy\n",
        "- Unlucky split → underestimate accuracy\n",
        "\n",
        "## 5-Fold Cross-Validation Results\n",
        "\n",
        "### Logistic Regression\n",
        "- Mean Accuracy: 79%\n",
        "- Standard Deviation: [your value]\n",
        "- Less stable across different data splits\n",
        "\n",
        "### Random Forest  \n",
        "- Mean Accuracy: 81%\n",
        "- Standard Deviation: [your value] (lower = more stable)\n",
        "- **Winner: More accurate AND more consistent** ✓\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Cross-validation provides:\n",
        "- More reliable accuracy estimates\n",
        "- Confidence intervals (mean ± std)\n",
        "- Model stability assessment\n",
        "\n",
        "Random Forest outperforms Logistic Regression in both accuracy and consistency."
      ],
      "metadata": {
        "id": "8IW8cKVexQ_6"
      }
    }
  ]
}